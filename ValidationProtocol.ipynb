{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.ensemble.forest import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingRegressor\n",
    "from sklearn.tree.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.linear_model.ridge import Ridge\n",
    "import sklearn.metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors.regression import KNeighborsRegressor\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "#Set the seed\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open the file\n",
    "file_open=open('train.csv')\n",
    "# Open the csv reader over the file\n",
    "csv_reader=csv.reader(file_open,delimiter=\",\")\n",
    "# Read the first line which is the header\n",
    "header=csv_reader.next()\n",
    "# Load the dataset contained in the file\n",
    "dataset=[]\n",
    "\n",
    "cnt=0\n",
    "for row in csv_reader:\n",
    "#    if cnt<1:\n",
    "#        print row\n",
    "#        cnt+=1\n",
    "    dataset.append(row)\n",
    "\n",
    "#print header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace the missing values\n",
    "for row in dataset:\n",
    "    row[header.index(\"VAR_0002\")] = float(row[header.index(\"VAR_0002\")]) if row[header.index(\"VAR_0002\")] != \"\" else -1\n",
    "#    row[header.index(\"VAR_0003\")] = float(row[header.index(\"VAR_0003\")]) if row[header.index(\"VAR_0003\")] != \"\" else -1\n",
    "#   row[header.index(\"VAR_0004\")] = float(row[header.index(\"VAR_0004\")]) if row[header.index(\"VAR_0004\")] != \"\" else -1\n",
    "#   row[header.index(\"VAR_0006\")] = float(row[header.index(\"VAR_0006\")]) if row[header.index(\"VAR_0006\")] != \"\" else -1\n",
    "#   row[header.index(\"VAR_0007\")] = float(row[header.index(\"VAR_0007\")]) if row[header.index(\"VAR_0007\")] != \"\" else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter the dataset based on the column name\n",
    "feature_to_filter=[\"VAR_0002\"]\n",
    "indexes_to_filter=[]\n",
    "for feature in feature_to_filter:\n",
    "    indexes_to_filter.append(header.index(feature))\n",
    "\n",
    "dataset_filtered=[]\n",
    "for row in dataset:\n",
    "    dataset_filtered.append([row[index] for index in indexes_to_filter])\n",
    "# Build the structure containing the target\n",
    "targets=[]\n",
    "for row in dataset:\n",
    "    targets.append(float(row[header.index(\"target\")]))\n",
    "\n",
    "IDVal = []\n",
    "for row in dataset:\n",
    "    IDVal.append(row[header.index(\"ID\")])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "#Split the datasets to have one for learning and the other for the test\n",
    "train_dataset=[]\n",
    "test_dataset=[]\n",
    "train_target=[]\n",
    "test_target=[]\n",
    "test_ID=[]\n",
    "\n",
    "for row,target in zip(dataset_filtered,targets):\n",
    "    \n",
    "    if random.random() < 0.1:\n",
    "        train_dataset.append(row)\n",
    "        train_target.append(target)\n",
    "    else:\n",
    "        test_dataset.append(row)\n",
    "        test_target.append(target)\n",
    "\n",
    "for row,target in zip(dataset_filtered,targets):\n",
    "    \n",
    "    full_dataset.append(row)\n",
    "        \n",
    "### Cross Validation ###\n",
    "\n",
    "#cv = StratifiedKFold(train_dataset, n_folds=4)\n",
    "\n",
    "###scoring\n",
    "#clf = svm.SVC(kernel='linear', C=1)\n",
    "clf=DecisionTreeClassifier()\n",
    "scores = cross_validation.cross_val_score(clf, train_dataset, train_target, cv=5) \n",
    "print \"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2)\n",
    "\n",
    "### getting the predictions ###\n",
    "#predicted = cross_validation.cross_val_predict(clf, train_dataset, train_target, cv=10)\n",
    "#print metrics.accuracy_score(train_target, predicted) \n",
    "clf.fit(train_dataset,train_target)\n",
    "predictions=clf.predict(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.499070578838\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the quality of the prediction\n",
    "#print sklearn.metrics.mean_absolute_error(predictions,test_target)\n",
    "\n",
    "### AUC ###\n",
    "#fpr, tpr, thresholds = sklearn.metrics.roc_curve(test_dataset, test_target, pos_label=2)\n",
    "#print sklearn.metrics.roc_auc_score(fpr, tpr)\n",
    "\n",
    "print roc_auc_score(test_target, predictions)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#open('submission.csv', 'w') as csvfile:\n",
    "#    fieldnames = ['ID', 'target']\n",
    "#    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "import csv\n",
    "from itertools import izip\n",
    "\n",
    "\n",
    "# Open the file\n",
    "file_open=open('test.csv')\n",
    "# Open the csv reader over the file\n",
    "csv_reader=csv.reader(file_open,delimiter=\",\")\n",
    "# Read the first line which is the header\n",
    "header=csv_reader.next()\n",
    "# Load the dataset contained in the file\n",
    "full_dataset=[]\n",
    "\n",
    "for row in csv_reader:\n",
    "    full_dataset.append(row)\n",
    "\n",
    "ids=[]\n",
    "\n",
    "for row in full_dataset:\n",
    "    ids.append(row[header.index(\"ID\")])\n",
    "    \n",
    "for row in full_dataset:\n",
    "    row[header.index(\"VAR_0002\")] = float(row[header.index(\"VAR_0002\")]) if row[header.index(\"VAR_0002\")] != \"\" else -1\n",
    "\n",
    "# Filter the dataset based on the column name\n",
    "feature_to_filter=[\"VAR_0002\"]\n",
    "indexes_to_filter=[]\n",
    "\n",
    "for feature in feature_to_filter:\n",
    "    indexes_to_filter.append(header.index(feature))\n",
    "\n",
    "dataset_filtered=[]\n",
    "for row in dataset:\n",
    "    dataset_filtered.append([row[index] for index in indexes_to_filter])\n",
    "predictionsOut=clf.predict(dataset_filtered)\n",
    "\n",
    "with open('submission.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"ID\",\"target\"])\n",
    "    writer.writerows(izip(ids, predictionsOut))\n",
    "\n",
    "#f = open(\"submission.csv\", \"w\")\n",
    "#f.write(\"ID\",\"target\")\n",
    "#for i in xrange(len(test_target)):\n",
    "#    f.write(\"{} {}\\n\".format(test_target[i], predictions[i]))\n",
    "\n",
    "#f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
